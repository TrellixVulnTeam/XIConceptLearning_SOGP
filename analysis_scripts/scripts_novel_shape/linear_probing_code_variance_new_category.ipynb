{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../ProtoLearning/\")\n",
    "from models.icsn import iCSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained(model, ckpt):\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "    model.proto_dict = ckpt['model_misc']['prototypes']\n",
    "    model.softmax_temp = ckpt['model_misc']['softmax_temp']\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_single_img(model, imgs, idx):\n",
    "    model.eval()\n",
    "    preds, recons = model.forward_single(imgs)\n",
    "\n",
    "    recons = recons.permute(0, 2, 3, 1).detach().cpu()\n",
    "    imgs = imgs.permute(0, 2, 3, 1).detach().cpu()\n",
    "    preds = preds.unsqueeze(dim=0).detach().cpu()\n",
    "    preds = preds[0, idx]\n",
    "    preds_as_ids = [torch.argmax(preds[model.attr_positions[i]:model.attr_positions[i+1]]).numpy() for i in range(model.n_groups)]\n",
    "\n",
    "    # convert to RGB numpy array\n",
    "    recons_np = recons[idx].squeeze().numpy()\n",
    "    # convert -1 1 range to 0 255 range for plotting\n",
    "    recons_np = ((recons_np - recons_np.min())\n",
    "              * (1 / (recons_np.max() - recons_np.min()) * 255)).astype('uint8')\n",
    "    fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(15, 10))\n",
    "    ax[0].imshow(imgs[idx])\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title(\"Input Img\");\n",
    "    ax[1].imshow(preds.unsqueeze(dim=0), cmap=cm.gray)\n",
    "    ax[1].axes.yaxis.set_visible(False)\n",
    "    ax[1].set_title(\"I believe it has these properties\");\n",
    "#     ax[1].set_xlabel(\"Attributes\");\n",
    "    ax[2].imshow(recons_np)\n",
    "    ax[2].axis('off')\n",
    "    ax[2].set_title(\"Because it is close to these composed prototypes:\");\n",
    "    plt.show()\n",
    "    \n",
    "    return fig, preds_as_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary to convert a label list of individual groups to a single id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_multilabel_to_label_id = {}\n",
    "id = 0\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        for k in range(2):\n",
    "            for l in range(2):\n",
    "                convert_multilabel_to_label_id[f'{i}{j}{k}{l}'] = id\n",
    "                id+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training and validation set containing old and new objects for linear probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data set\n",
    "train_probing_data_path = f\"../Data/ECR/train_probing/train_probing_ecr_spot.npy\"\n",
    "train_probing_labels_path = f\"../Data/ECR/train_probing/train_probing_ecr_spot_labels.pkl\"\n",
    "\n",
    "train_probing_imgs = np.load(train_probing_data_path, allow_pickle=True)\n",
    "train_probing_imgs = (train_probing_imgs - train_probing_imgs.min()) / (train_probing_imgs.max() - train_probing_imgs.min())\n",
    "\n",
    "with open(train_probing_labels_path, 'rb') as f:\n",
    "    labels_dict = pickle.load(f)\n",
    "    train_probing_labels = labels_dict['labels']\n",
    "  \n",
    "train_probing_imgs = torch.tensor(np.moveaxis(train_probing_imgs, (0, 1, 2, 3), (0, 2, 3, 1)))\n",
    "train_probing_imgs = train_probing_imgs.type('torch.FloatTensor')\n",
    "train_probing_labels = torch.tensor(train_probing_labels)    \n",
    "\n",
    "# convert multi label to single label\n",
    "train_probing_labels = train_probing_labels.int()\n",
    "# single_train_probing_labels = torch.tensor([convert_multilabel_to_label_id[f'{train_probing_labels[i][0].item()}{train_probing_labels[i][1].item()}{train_probing_labels[i][2].item()}'] for i in range(train_probing_labels.shape[0])])\n",
    "\n",
    "train_probing_dataset = torch.utils.data.TensorDataset(train_probing_imgs, train_probing_labels)\n",
    "train_probing_dataloader = torch.utils.data.DataLoader(train_probing_dataset, batch_size=len(train_probing_dataset),\n",
    "                                                  shuffle=True)\n",
    "\n",
    "# val data set\n",
    "val_data_path = f\"../Data/ECR/val_ecr_spot.npy\"\n",
    "val_labels_path = f\"../Data/ECR/val_ecr_spot_labels.pkl\"\n",
    "\n",
    "val_imgs = np.load(val_data_path, allow_pickle=True)\n",
    "val_imgs = (val_imgs - val_imgs.min()) / (val_imgs.max() - val_imgs.min())\n",
    "\n",
    "with open(val_labels_path, 'rb') as f:\n",
    "    labels_dict = pickle.load(f)\n",
    "    val_labels = labels_dict['labels']\n",
    "  \n",
    "val_imgs = torch.tensor(np.moveaxis(val_imgs, (0, 1, 2, 3), (0, 2, 3, 1)))\n",
    "val_imgs = val_imgs.type('torch.FloatTensor')\n",
    "val_labels = torch.tensor(val_labels)    \n",
    "\n",
    "# convert multi label to single label\n",
    "val_labels = val_labels.int()\n",
    "# single_val_labels = torch.tensor([convert_multilabel_to_label_id[f'{val_labels[i][0].item()}{val_labels[i][1].item()}{val_labels[i][2].item()}'] for i in range(val_labels.shape[0])])\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(val_imgs, val_labels)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=len(val_dataset),\n",
    "                                                  shuffle=True)\n",
    "\n",
    "# get data from loader\n",
    "train_probing_imgs, train_probing_label_ids = next(iter(train_probing_dataloader))\n",
    "val_imgs, val_label_ids = next(iter(val_dataloader))\n",
    "\n",
    "# convert multilabel to single label\n",
    "train_probing_single_labels = torch.tensor([convert_multilabel_to_label_id[\n",
    "    f'{train_probing_label_ids[i][0].item()}'+\n",
    "    f'{train_probing_label_ids[i][1].item()}'+\n",
    "    f'{train_probing_label_ids[i][2].item()}'+\n",
    "    f'{train_probing_label_ids[i][3].item()}'\n",
    "] for i in range(train_probing_label_ids.shape[0])])\n",
    "val_single_labels = torch.tensor([convert_multilabel_to_label_id[\n",
    "    f'{val_label_ids[i][0].item()}'+\n",
    "    f'{val_label_ids[i][1].item()}'+\n",
    "    f'{val_label_ids[i][2].item()}'+\n",
    "    f'{val_label_ids[i][3].item()}'\n",
    "] for i in range(val_label_ids.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance calculation for Proto-Swap-AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ../WeakAEProtoLearning/runs/ae-swap-rr-0-simpleshapescolorvarshapesizenospotpairsmult-trainprotos-nopretrain-666-extramlp/states/00999.pth\n",
      "tensor(0.0527)\n",
      "tensor(0.0470)\n",
      "Loading model ../WeakAEProtoLearning/runs/ae-swap-rr-1-simpleshapescolorvarshapesizenospotpairsmult-trainprotos-nopretrain-666-extramlp/states/00999.pth\n",
      "tensor(0.0008)\n",
      "tensor(0.)\n",
      "Loading model ../WeakAEProtoLearning/runs/ae-swap-rr-3-simpleshapescolorvarshapesizenospotpairsmult-trainprotos-nopretrain-666-extramlp/states/00999.pth\n",
      "tensor(0.0251)\n",
      "tensor(0.0215)\n",
      "Loading model ../WeakAEProtoLearning/runs/ae-swap-rr-13-simpleshapescolorvarshapesizenospotpairsmult-trainprotos-nopretrain-666-extramlp/states/00999.pth\n",
      "tensor(0.)\n",
      "tensor(0.0004)\n",
      "Loading model ../WeakAEProtoLearning/runs/ae-swap-rr-21-simpleshapescolorvarshapesizenospotpairsmult-trainprotos-nopretrain-666-extramlp/states/00999.pth\n",
      "tensor(0.0155)\n",
      "tensor(0.0138)\n",
      "Loading model ../WeakAEProtoLearning/runs/ae-swap-0-simpleshapescolorvarshapesizespotpairsmult-trainprotos-nopretrain-6666/states/01999.pth\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "Loading model ../WeakAEProtoLearning/runs/ae-swap-1-simpleshapescolorvarshapesizespotpairsmult-trainprotos-nopretrain-6666/states/01999.pth\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "Loading model ../WeakAEProtoLearning/runs/ae-swap-3-simpleshapescolorvarshapesizespotpairsmult-trainprotos-nopretrain-6666/states/01999.pth\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "Loading model ../WeakAEProtoLearning/runs/ae-swap-13-simpleshapescolorvarshapesizespotpairsmult-trainprotos-nopretrain-6666/states/01999.pth\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "Loading model ../WeakAEProtoLearning/runs/ae-swap-21-simpleshapescolorvarshapesizespotpairsmult-trainprotos-nopretrain-6666/states/01999.pth\n",
      "tensor(0.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "def compute_code_and_variance(model, imgs, gt_labels_ids, config):\n",
    "    collect_codes = {}\n",
    "\n",
    "    try:\n",
    "        codes, _ = model.forward_single(imgs)\n",
    "    except:\n",
    "        _, codes = model.forward(imgs)\n",
    "        codes = codes.squeeze(dim=2)\n",
    "\n",
    "    # for every GT attribute collect the codes from each model and data set\n",
    "    for cat_id in range(0, 3):\n",
    "        \n",
    "        for concept_id in range(0, 4):\n",
    "        \n",
    "            # find those samples that have the same concept in the specified category identifier\n",
    "            rel_ids = torch.where(gt_labels_ids.T[cat_id] == concept_id)[0]\n",
    "            \n",
    "            # filter out the model code for those samples in the specified category identifier\n",
    "            try:\n",
    "                rel_codes = codes[rel_ids, \n",
    "                                   config['prototype_cumsum'][cat_id]:config['prototype_cumsum'][cat_id+1]]\n",
    "            except:\n",
    "                rel_codes = codes[rel_ids, cat_id]\n",
    "            \n",
    "            # store the individual codes\n",
    "            collect_codes[f\"{str(cat_id)}-{str(concept_id)}\"] = rel_codes.detach().cpu()\n",
    "\n",
    "    collect_variance = {}\n",
    "\n",
    "    sum_variance = 0.\n",
    "\n",
    "    # iterate over each GT attribute and compute the code variance at the relevant factor id\n",
    "    for cat_id in range(0, 3):\n",
    "    \n",
    "        for concept_id in range(0, 4):\n",
    "            \n",
    "            var = torch.sum(torch.var(collect_codes[f\"{str(cat_id)}-{str(concept_id)}\"], dim=0))\n",
    "\n",
    "            if not torch.isnan(var):\n",
    "            \n",
    "                collect_variance[f\"{str(cat_id)}-{str(concept_id)}\"] = var\n",
    "                \n",
    "                sum_variance += var\n",
    "                 \n",
    "    sum_variance /= len(collect_variance.keys())\n",
    "    \n",
    "    print(sum_variance)\n",
    "\n",
    "    return {'codes': codes, 'collect_codes': collect_codes, \n",
    "                                  'variances': collect_variance, 'avg_variance': sum_variance}\n",
    "\n",
    "# load prosa models trained without novel category\n",
    "icsn_prior_results_all = {}\n",
    "for model_id in [0, 1, 3, 13, 21]:    \n",
    "    ckpt_fp = f\"../ProtoLearning/runs/icsn-rr-{model_id}-ecr-extramlp/states/00999.pth\"\n",
    "    print(f\"Loading model {ckpt_fp}\")\n",
    "    ckpt = torch.load(ckpt_fp, map_location=torch.device('cpu'))\n",
    "    config = ckpt['config']\n",
    "    config['device'] = 'cpu'\n",
    "    config['data_dir'] = '../Data/ECR/'\n",
    "\n",
    "    icsn_prior_model = iCSN(num_hiddens=64, num_residual_layers=2, num_residual_hiddens=64,\n",
    "                    n_proto_vecs=config['prototype_vectors'], enc_size=config['enc_size'],\n",
    "                    proto_dim=config['proto_dim'], softmax_temp=config['temperature'],\n",
    "                    extra_mlp_dim=config['extra_mlp_dim'],\n",
    "                    multiheads=config['multiheads'], train_protos=config['train_protos'],\n",
    "                    device=config['device'])\n",
    "\n",
    "    icsn_prior_model = icsn_prior_model.to(config['device'])\n",
    "    icsn_prior_model = load_pretrained(icsn_prior_model, ckpt)\n",
    "    icsn_prior_model.temperature = 0.000001\n",
    "    icsn_prior_model.eval();\n",
    "        \n",
    "    train_result_dict = compute_code_and_variance(model=icsn_prior_model, imgs=train_probing_imgs, \n",
    "                                                  gt_labels_ids=train_probing_label_ids, config=config)\n",
    "    val_result_dict = compute_code_and_variance(model=icsn_prior_model, imgs=val_imgs, \n",
    "                                                  gt_labels_ids=val_label_ids, config=config)\n",
    "\n",
    "    icsn_prior_results_all[model_id] = {'train': train_result_dict, 'val': val_result_dict}\n",
    "\n",
    "# load prosa models trained with novel category\n",
    "icsn_post_results_all = {}\n",
    "for model_id in [0, 1, 3, 13, 21]:    \n",
    "    ckpt_fp = f\"../ProtoLearning/runs/icsn-{model_id}-ecr-6666/states/01999.pth\"\n",
    "    print(f\"Loading model {ckpt_fp}\")\n",
    "    ckpt = torch.load(ckpt_fp, map_location=torch.device('cpu'))\n",
    "    config = ckpt['config']\n",
    "    config['device'] = 'cpu'\n",
    "    config['data_dir'] = '../Data/ECR/'\n",
    "\n",
    "    icsn_post_model = iCSN(num_hiddens=64, num_residual_layers=2, num_residual_hiddens=64,\n",
    "                    n_proto_vecs=config['prototype_vectors'], enc_size=config['enc_size'],\n",
    "                    proto_dim=config['proto_dim'], softmax_temp=config['temperature'],\n",
    "                    extra_mlp_dim=config['extra_mlp_dim'],\n",
    "                    multiheads=config['multiheads'], train_protos=config['train_protos'],\n",
    "                    device=config['device'])\n",
    "\n",
    "    icsn_post_model = icsn_post_model.to(config['device'])\n",
    "    icsn_post_model = load_pretrained(icsn_post_model, ckpt)\n",
    "    icsn_post_model.temperature = 0.000001\n",
    "    icsn_post_model.eval();\n",
    "        \n",
    "    train_result_dict = compute_code_and_variance(model=icsn_post_model, imgs=train_probing_imgs, \n",
    "                                                  gt_labels_ids=train_probing_label_ids, config=config)\n",
    "    val_result_dict = compute_code_and_variance(model=icsn_post_model, imgs=val_imgs, \n",
    "                                                  gt_labels_ids=val_label_ids, config=config)\n",
    "\n",
    "    icsn_post_results_all[model_id] = {'train': train_result_dict, 'val': val_result_dict}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "ProSA with prior novel category\n",
      "------------------------------------------------------\n",
      "ProSA with post novel category\n",
      "------------------------------------------------------\n",
      "------------------------Mean--------------------------\n",
      "------------------------------------------------------\n",
      "Mean acc. Prosa prior\n",
      "DT: 93.1 4.459147900664428\n",
      "LR:  67.54 9.071901674952175\n",
      "\n",
      "Mean acc. Prosa post\n",
      "DT: 99.85 0.3\n",
      "LR:  98.28999999999999 3.4199999999999986\n",
      "\n",
      "------------------------------------------------------\n",
      "----------------------Median--------------------------\n",
      "------------------------------------------------------\n",
      "Median acc. Prosa prior\n",
      "DT: 95.45 4.459147900664428\n",
      "LR:  65.7 9.071901674952175\n",
      "\n",
      "Median acc. Prosa post\n",
      "DT: 100.0 0.3\n",
      "LR:  100.0 3.4199999999999986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fit_and_predict_lr_dt(results_dict, gt_single_labels_val, model_seed_id, verbose=0):\n",
    "\n",
    "    codes_train = results_dict[model_seed_id]['train']['codes']\n",
    "    codes_val = results_dict[model_seed_id]['val']['codes']\n",
    "\n",
    "    # decision tree\n",
    "    clf_icsn_dt = DecisionTreeClassifier(random_state=21, max_depth=8)\n",
    "    clf_icsn_dt.fit(codes_train.detach().cpu().numpy(), train_probing_single_labels.numpy())\n",
    "\n",
    "    # Perform logistic regression\n",
    "    clf_icsn_lr = LogisticRegression(random_state=0, C=0.316, max_iter=1000)\n",
    "    clf_icsn_lr.fit(codes_train.detach().cpu().numpy(), train_probing_single_labels.numpy())\n",
    "\n",
    "    # Evaluate using the classifiers\n",
    "    predictions_dt = clf_icsn_dt.predict(codes_val.detach().cpu().numpy())\n",
    "    predictions_lr = clf_icsn_lr.predict(codes_val.detach().cpu().numpy())\n",
    "\n",
    "    accuracy_dt = np.mean((gt_single_labels_val.numpy() == predictions_dt).astype(np.float)) * 100.\n",
    "    accuracy_lr = np.mean((gt_single_labels_val.numpy() == predictions_lr).astype(np.float)) * 100.\n",
    "\n",
    "    if verbose > 0:\n",
    "        print(f\"\\nSeed {model_seed_id} Val accuracy DT codes = {accuracy_dt:.3f}\")\n",
    "        print(f\"Seed {model_seed_id} Val accuracy LR codes = {accuracy_lr:.3f}\")\n",
    "    return accuracy_dt, accuracy_lr\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print('iCSN with prior novel category')\n",
    "acc_icsn_prior_dt = []\n",
    "acc_icsn_prior_lr = []\n",
    "code_vars_icsn_prior_val = []\n",
    "for seed_id in [0, 1, 3, 13, 21]:\n",
    "    \n",
    "    accuracy_dt, accuracy_lr = fit_and_predict_lr_dt(results_dict=icsn_prior_results_all, \n",
    "                                                     gt_single_labels_val=val_single_labels, model_seed_id=seed_id)\n",
    "    acc_icsn_prior_dt.append(accuracy_dt)\n",
    "    acc_icsn_prior_lr.append(accuracy_lr)\n",
    "    \n",
    "    code_vars_icsn_prior_val.append(icsn_prior_results_all[seed_id]['val']['avg_variance'])\n",
    "\n",
    "    \n",
    "print('------------------------------------------------------')\n",
    "print('iCSN with post novel category')\n",
    "acc_icsn_post_dt = []\n",
    "acc_icsn_post_lr = []\n",
    "code_vars_icsn_post_val = []\n",
    "for seed_id in [0, 1, 3, 13, 21]:\n",
    "    \n",
    "    accuracy_dt, accuracy_lr = fit_and_predict_lr_dt(results_dict=icsn_post_results_all, \n",
    "                                                     gt_single_labels_val=val_single_labels, model_seed_id=seed_id)\n",
    "    acc_icsn_post_dt.append(accuracy_dt)\n",
    "    acc_icsn_post_lr.append(accuracy_lr)\n",
    "    \n",
    "    code_vars_icsn_post_val.append(icsn_post_results_all[seed_id]['val']['avg_variance'])\n",
    "\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print('------------------------Mean--------------------------')\n",
    "print('------------------------------------------------------')\n",
    "print(f\"Mean acc. Prosa prior\\nDT: {np.mean(acc_icsn_prior_dt)} {np.std(acc_icsn_prior_dt)}\"+\n",
    "      f\"\\nLR:  {np.mean(acc_icsn_prior_lr)} {np.std(acc_icsn_prior_lr)}\\n\")\n",
    "print(f\"Mean acc. Prosa post\\nDT: {np.mean(acc_icsn_post_dt)} {np.std(acc_icsn_post_dt)}\"+\n",
    "      f\"\\nLR:  {np.mean(acc_icsn_post_lr)} {np.std(acc_icsn_post_lr)}\\n\")\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print('----------------------Median--------------------------')\n",
    "print('------------------------------------------------------')\n",
    "print(f\"Median acc. Prosa prior\\nDT: {np.median(acc_icsn_prior_dt)} {np.std(acc_icsn_prior_dt)}\"+\n",
    "      f\"\\nLR:  {np.median(acc_icsn_prior_lr)} {np.std(acc_icsn_prior_lr)}\\n\")\n",
    "print(f\"Median acc. Prosa post\\nDT: {np.median(acc_icsn_post_dt)} {np.std(acc_icsn_post_dt)}\"+\n",
    "      f\"\\nLR:  {np.median(acc_icsn_post_lr)} {np.std(acc_icsn_post_lr)}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}